---
layout: post  
title: 인공신경망  
description: Deep learning  
---

### 1. 퍼셉트론의 수학적 접근

![사진](/assets/images/deep_learning/2018-10-07/ch03.png)

x1과 x2의 입력값을 받는 퍼셉트론이다. 그림을 수식으로 정리해보면 
다음과 같다.
~~~
y = 0 (b + w1 * x1 + w2 * x2 <= 0)
y = 1 (b + w1 * x1 + w2 * x2 > 0)
~~~

여기서 다음과 같이 정리하면

~~~
h(a) = b + w1 * x1 + w2 * x2  이라 하면

y = h(a) 이고

h(a) = 0, 1의 값을 가지게 된다.
~~~

여기서 a = b + w1 * x1 + w2 * x2 가 되고, y는 함수 h(a)에 결과값이 된다.
그리고 a는 함수 h(a)에 입력값이 되면 a 값에 의해서 y의 활성화 정도가 결정되게 된다.
그래서 수식 h(a)의 이름을 ***활성화 함수*** 라고 한다.

### 2. 활성화 함수
퍼셉트론의 결과값(y)는 언제나 0, 1이다. 2가지 값만 존재하기 때문에 중간값에
대한 처리가 불가능하다. 인공신경망에서는 0, 1의 사이의 값이 유연하게 연결되어 있는
시그모이드(sigmoid)함수, 렐루(relu)함수를 대표적인 활성화 함수로 이용하게 된다.


>#### 시그모이드 함수
> 시그모이드 함수를 파이썬으로 구현해 보자
> ~~~
> def sigmoid(x):
>       return 1 / (1 + numpy.exp(-x))
> ~~~
>
>#### 렐루 함수
> 렐루 함수를 파이썬으로 구현해 보자
> ~~~
> def relu(x):
>       return numpy.maximum(0, x)
> ~~~